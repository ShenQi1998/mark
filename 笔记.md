[TOC]



# JAVA

## 面向对象编程

封装，继承和多态

封装：隐藏对象的属性和实现细节，仅对外提供公共访问方式，将变化隔离，便于使用，提高复用性和安全性。 

继承：继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父 类的功能，但不能选择性地继承父类。通过使用继承可以提高代码复用性。继承是多态的前提。 关于继承如下 3 点请记住：
①. 子类拥有父类非 private 的属性和方法。 
②. 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。 
③. 子类可以用自己的方式实现父类的方法。 

多态性：父类或接口定义的引用变量可以指向子类或具体实现类的实例对象。提高了程序的拓展性。 在Java中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。 方法重载（overload）实现的是编译时的多态性（也称为前绑定），而方法重写（override）实现的是运行时的多态性 （也称为后绑定）。 

一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运 行期间才能决定。运行时的多态是面向对象最精髓的东西，要实现多态需要做两件事：

重写：子类继承父类并重写父类中已有的或抽象的方法
对象造型：用父类型引用子类型对象，这样同样的引用调用同样的方法就会根据子类对象的不同而表现出不同的行为。



## JDK JRE JVM

JDK>JRE>JVM

JVM:Java虚拟机,Java虚拟机有自己完善的硬体架构和相应的指令系统，因为有JVM的存在，使得JAVA可以跨平台使用。

![](.\image\5.png)

## 抽象类的特点

①抽象类不能被实例化
②构造方法 和 static 方法不能是抽象的
③父类的抽象方法往往在子类中实现
④抽象类可以具有指向子类对象的对象引用

 

## 接口和抽象类

①抽象类可以存在普通成员函数(非抽象的方法)，而接口中只能存在public abstract 方法
②抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是public static final(默认)类型的
③在JAVA中，一个类可以实现多个接口，但是只能实现一个抽象类
④一个类要实现接口的所有方法，而抽象类则不一定
⑤接口，抽象类都不可以被实例化，但是，如果抽象类的main方法可以被调用的。

PS
接口设计的目的，是对类中方法的有无进行约束，对具体的实现不进行各种限制。
抽象类的设计目的，是为了代码复用，例如多个类中有相同的方法，抽取相同的方法组成新的类。因为抽象类中有一些方法并没有具体的实现，所以不能实例化。



## 重写和重载

重写：子类继承父类并重写父类中已有的或抽象的方法（也称为覆盖) 
①子类应与父类有完全相同的方法名，返回值类型和参数列表，
②子类中的覆盖方法不能使用比父类中被覆盖的方法更严格的访问权限。
③调用时会使用自动使用的方法，在方法前super关键字，才能使用父类之前的方法。

重载：
①方法名一样，传入的参数和返回值不同。



## 什么是构造函数？什么是构造函数重载？

当新对象被创建的时候，构造函数会被调用。每一个类都有构造函数。在程序员没有给类提供构造函数的情况下，Java编译器会为这个类创建一个默认的构造函数。
Java中构造函数重载和方法重载很相似。可以为一个类创建多个构造函数。每一个构造函数必须有它自己唯一的参数列表。



## new的作用

1、为对象分配内存空间，将对象的实例变量自动初始化为其变量类型的默认值。
2、如果实例变量在声明时被显式初始化，那就把初始化值赋给实例变量。
3、调用构造方法。
4、返回对象的引用。

## final的作用

修饰类：不可以被继承(不可以有子类)
修饰方法：不可以被子类重写，但是可以重载
修饰变量：不可以更改变量值



## 为什么局部内部类和匿名内部类只能访问局部final变量

编译后，会生成外部类和内部类两个class文件，当执行完外部的方法后，外部类就会被销毁。这时内部类可能还没有执行完，就可能存在找不到外部类定义的变量的情况，所以需要将外部类copy一份到内部类，来延长局部类的生命周期。这样就可能出现一个问题，变量在外部类和内部类可能不相同，为了解决这个问题，就讲内部类变量设置为final.对他初始化之后，就不允许修改了。这实际上是一种妥协，使得局部变量与内部类建立的拷贝保持一致。



## 数组(Array)和列表(ArrayList)有什么区别？什么时候应该使用Array而不是ArrayList？

下面列出了Array和ArrayList的不同点：

Array可以包含基本类型和对象类型，ArrayList只能包含对象类型。
Array大小是固定的，ArrayList的大小是动态变化的。
ArrayList提供了更多的方法和特性，比如：addAll()，removeAll()，iterator()等等。



## Java中Exception和Error有什么区别？

Exception和Error都是Throwable的子类。Exception用于用户程序可以捕获的异常情况。Error定义了不期望被用户程序捕获的异常。

Throwable下有两个分支：Error(不可处理，直接退出JVM)和Exception(可处理的)

Exception下有两个分支：
Exception的直接子类：编译时异常(要求程序员在编写程序阶段必须预先对这些异常进行处理，不处理，编译不通过)
编译时异常也被称为：受检异常(CheckedException)、受控异常。
RuntimeException：运行时异常(在编写程序阶段程序员可以处理，也可以不处理)。
运行时异常也被称为：未受检异常(UnCheckedException)、非受控异常。



## 权限修饰符用于限定变量或者方法的使用范围?

|                       | 本类中 | 同包类中 | 子类中               | 其他类中 |
| --------------------- | ------ | -------- | -------------------- | -------- |
| Public（公共的）      | 可以   | 可以     | 可以                 | 可以     |
| Protected（受保护的） | 可以   | 可以     | 可以                 | 不可以   |
| default（默认）       | 可以   | 可以     | 不可以(同包子类可以) | 不可以   |
| Private（私有）       | 可以   | 不可以   | 不可以               | 不可以   |



## Comparable和Comparator接口

Comparable接口只包含compareTo()，Comparator包含了compare()和equals()两个方法
compareTo()和compare()返回负数，0，正数来表明输入对象小于，等于，大于已经存在的对象



## ==和equals比较

==比较的栈中的值，基本数据类型比较的是变量值，引用数据类型比较的是对象的内存地址
equals是对==的一种重写，其会先和==比较，不相同的话循环比较每个字节。

PS
String a = "111"; String b = "111"  变量储存在堆中的常量区,且a,b两个变量指向的同一块内存，所以 a==b 为true
String c = new String ("111") 会在堆中重新建立一块内存，所以 a==c 为false



## 值传递和引用传递

值传递：是指在调用函数时，将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，就不会影响到实际参数
引用传递：是指在调用函数时，将实际参数的地址传递到函数中，那么在函数中对参数进行修改，将会影响到实际参数
注意点，引用类型中的String的值是放在常量池中，我们改变副本的值不会影响到原来的值。**



## 什么是Java优先级队列(Priority Queue)

PriorityQueue是一个基于优先级堆的无界队列，它的元素是按照自然顺序(natural order)排序的。在创建的时候，我们可以给它提供一个负责给元素排序的比较器。PriorityQueue不允许null值，因为他们没有自然顺序，或者说他们没有任何的相关联的比较器。最后，PriorityQueue不是线程安全的，入队和出队的时间复杂度是O(log(n))。



## 深克隆和浅克隆

区别

1、浅克隆:对当前对象进行克隆,并克隆该对象所包含的8种基本数据类型和String类型属性（拷贝一份该对象并重新分配内存，即产生了新的对象）；但如果被克隆的对象中包含除8中数据类型和String类型外的其他类型的属性,浅克隆并不会克隆这些属性（即不会为这些属性分配内存，而是引用原来对象中的属性）。
2、深克隆:深克隆是在浅克隆的基础上，递归地克隆除8种基本数据类型和String类型外的属性（即为这些属性重新分配内存而非引用原来对象中的属性）

特点

1、被克隆的对象的类应实现 Cloneable 接口，并重写 clone() 方法，深克隆的类必须实现 Cloneable ,Serializable 接口；
2、浅克隆中由于除8中数据类型和String类型外的其他类型的属性不会被克隆，因此当通过新对象对这些属性进行修改时，原对象的属性也会同时改变。而深克隆则已经对这些属性重新分配内存，所以当通过新对象对这些属性进行修改时，原对象的属性不会改变。



## 类加载机制-双亲委托机制

例如：当jvm要加载Test.class的时候，

　　（1）首先会到自定义加载器中查找，看是否已经加载过，如果已经加载过，则返回字节码。
　　（2）如果自定义加载器没有加载过，则询问上一层加载器 (即AppClassLoader) 是否已经加载过Test.class。
 	   （3）如果没有加载过，则询问上一层加载器（ExtClassLoader）是否已经加载过。
　　（4）如果没有加载过，则继续询问上一层加载（BoopStrap ClassLoader）是否已经加载过。
		（5）如果BoopStrap ClassLoader依然没有加载过，则到自己指定类加载路径下（"sun.boot.class.path**"**）查看是否有Test.class字节码，有则返回，没有通知下一层加载器ExtClassLoader到自己指定的类加载路径下（java.ext.dirs）查看。
　　（6）依次类推，最后到自定义类加载器指定的路径还没有找到Test.class字节码，则抛出异常ClassNotFoundException。如下图：

![4](.\image\4.png)





## Collection和Collections有什么区别

Collection是一个集合接口，它提供了对集合对象进行基本操作的通用接口方法，所有集合都是它的子类，比如List,Set等。

Collections是一个包装类，包含了很多静态方法，不能被实例化，就像一个工具类，比如提供的排序方法.sort



## Collection,Set,List,Map等的关系

实线是继承，虚线是实线

![1](.\image\1.jpg)

## 快速失败(fail-fast)和安全失败(fail-safe)的区别是什么？

快速失败：在用迭代器]遍历一个集合对象时，如果遍历过程中对集合对象的结构进行了修改（增加、删除），则会抛出Concurrent Modification Exception.
原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个modCount数量，集合在被遍历期间如果结构发生变化，就会改变modCount的值。每当迭代器使用hasNext()/next()遍历下一个元素之前，都会检测modCount变量是否等于expectedmodCount的值，是的话就返回遍历；否则抛出异常，终止遍历。

安全失败：采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。
原理： 由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到。所以不会触发Concurrent Modification Exception.

例：HashMap迭代器的强一致性不同。
ConcurrentHashMap迭代器是弱一致性。



## List，Set，Map之间的区别是什么

List:有序，按照对象进入的顺序保存，可以重复，允许多个null元素对象，可以使用iterator(迭代器)取出所有元素进行遍历，可以使用get(index)对指定下标进行操作。

Set:无序，不可重复，最多有一个null元素对象，取元素只能用iterator(迭代器)取出所有元素进行遍历。

![3](G:\笔记\image\3.jpg)



## HashSet和TreeSet有什么区别？

HashSet是由一个hash表来实现的，因此，它的元素是无序的。add()，remove()，contains()方法的时间复杂度是O(1)。
另一方面，TreeSet是由一个树形的结构来实现的，它里面的元素是有序的。因此，add()，remove()，contains()方法的时间复杂度是O(logn)。



## Enumeration接口和Iterator接口的区别有哪些？

Enumeration速度是Iterator的2倍，同时占用更少的内存。但是，Iterator远远比Enumeration安全，因为其他线程不能够修改正在被iterator遍历的集合里面的对象。同时，Iterator允许调用者删除底层集合里面的元素，这对Enumeration来说是不可能的。



## ArrayList和linkedList的区别

ArrayList和LinkedList都实现了List接口，他们有以下不同

①数据结构不同
ArrayList是基于数组，LinkedList基于链表的。

②对特定操作的效率不同
由于ArryList是下标索引，当进行对某个元素get或者set时ArryList效率更高，在对非尾部元素进行增加，删除操作是较慢，它会对操作点之后所有数据的下标索引造成影响，需要进行数据的移动。LinkedList是线性的存储方式，进行增加，删除操作的时候更快，但是对某个元素进行get和set时会较慢。

③内存占用方式不同
ArrayList比LinkedList更占更少的内存，因为ArrayList是占据整块连续的内存，LinkedList的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素。



## vector和Arraylist

vector和Arraylist类似，vector是线程同步的，某一时刻只有一个线程能够写Vector，而Arraylist是线程异步的，是不安全的。如果不考虑到线程的安全因素，一般用Arraylist效率比较高。

如果集合中的元素的数目大于目前集合数组的长度时，vector增长率为目前数组长度的100%,而arraylist增长率为目前数组长度的50%.如过在集合中使用数据量比较大的数据，用vector有一定的优势，因为不需要过多的扩容操作。



## HashMap和HashTable的区别

1）HashMap允许key和value为null，而HashTable不允许
2）HashMap线程不安全,在单线程和多线程的执行结果可能不同,HashTable在所有方法中都加了synchronized，是线程安全的。
3）遍历方式不同 HashMap的Iterator是fail-fast的，提供对key的Set进行遍历；HashTable不支持fail-fast，提供对key的Enumeration进行遍历
4）计算hash值的方法不同  ,Hashtable在计算元素的位置时需要进行一次除法运算，而除法运算是比较耗时的。
HashMap为了提高计算效率，将哈希表的大小固定为了2的幂，这样在取模预算时，不需要做除法，只需要做位运算。位运算比除法的效率要高很多。



## 什么是ConcurrentHashMap

它由多个 Segment 组合而成。Segment 本身就相当于一个 HashMap 对象。同 HashMap 一样，Segment 包含一个 HashEntry 数组，数组中的每一个 HashEntry 既是一个键值对，也是一个链表的头节点。

相比于hashtable,ConcurrentHashMap效率更高，Put 操作时，锁的是某个 Segment，其他线程对其他 Segment 的读写操作均不影响。

JDK1.8中的ConcurrentHashMap，取消了Segment分段锁的数据结构，选择了与HashMap相同的数组+链表+红黑树结构；在锁的实现上，抛弃了原有的Segment分段锁，采用CAS+synchronized实现更加低粒度的锁。



## ConcurrentHashMap的put方法执行逻辑是什么？

JDK1.7：
首先会尝试获取锁，如果获取失败，利用自旋获取锁；如果自旋重试的次数超过64次，则改为阻塞获取。
获取到锁后：
1.将当前Segment中的table通过key的hashCode定位到HashEntry。
2.遍历该HashEntry，如果不为空则判断传入的keyhe当前遍历的key是否相等，相等则覆盖旧的value
3.不为空则需要新建一个HashEntry加入到Segment中，同时会先判断是否需要扩容
4.释放Segment的锁

JDK1.8：
1.根据key计算出hash值
2.判断是否需要进行初始化
3.定位到Node，拿到首节点，判断首节点
如果为null，则通过cas的方式尝试添加
如果f.hash ==MOVED = -1,说明其他线程在扩容，参与一起扩容
如果都不满足，synchronized锁住f节点，判断是链表还是红黑树，遍历插入、
4.当链表长度达到8的时候，数组扩容或者链表转换为红黑树

## ConcurrentHashMap的get方法是否要加锁，为什么？

get方法不需要加锁。因为Node的元素val和指针next是用volatile修饰的，在多线程环境下线程A修改结点的val或者新增节点的时候是对线程B可见的。


## ConcurrentHashMap的Size方法

1.遍历所有的Segment。
2.把Segment的元素数量累加起来。
3.把Segment的修改次数累加起来。
4.判断所有Segment的总修改次数是否大于上一次的总修改次数。如果大于，说明统计过程中有修改，重新统计，尝试次数+1；如果不是。说明没有修改，统计结束。
5.如果尝试次数超过阈值，则对每一个Segment加锁，再重新统计。
6.再次判断所有Segment的总修改次数是否大于上一次的总修改次数。由于已经加锁，次数一定和上次相等。
7.释放锁，统计结束。



## HashMap实现原理

HashMap基于Hash算法实现的。

1.7
1）若对象(数组)是空，会初始化Entry
2）如果key是null,单独处理。
3）根据key.hashCode()计算出hash值，根据hash值获取下标
4）根据hash值将value保存在bucket里。
当计算出的hash值相同时，我们称之为hash冲突，HashMap的做法是用链表和红黑树储存相同hash值得value。当hash冲突的个数比较少时，使用链表否则使用红黑树。



## JDK1.7和JDK1.8 HashMap发生了哪些变化
①1.7底层是数组+链表  1.8是数组+链表+红黑树 加入红黑树是为了提高插入和查询的整体效率
②1.7中链表是头插法，1.8中是尾插法。因为1.8中插入key和value需要判断元素的个数，所以需要遍历整个链表，所以采用尾插法
③1.7哈希算法更复杂，分布均匀，1.8中进行可简化，虽然散列化不如1.7均匀，但是由于红黑树的存在，使得整体效率提高了







## 创建线程有几种不同的方式

有三种方式可以用来创建线程：

继承Thread类  缺点：java是单继承的，故无法再继承其他类。

实现Runnable接口

使用Callable和Future创建线程

实现Runnable接口这种方式更受欢迎，因为这不需要继承Thread类。在应用设计中已经继承了别的对象的情况下，这需要多继承（而Java不支持多继承），只能实现接口。同时，线程池也是非常高效的，很容易实现和使用。



## 线程的几种状态

就绪(Runnable):线程准备运行，不一定立马就能开始执行。
运行中(Running)：进程正在执行线程的代码。
等待中(Waiting):线程处于阻塞的状态，等待外部的处理结束。
睡眠中(Sleeping)：线程被强制睡眠。
I/O阻塞(Blocked on I/O)：等待I/O操作完成。
同步阻塞(Blocked on Synchronization)：等待获取锁。
死亡(Dead)：线程完成了执行。



## ThreadLocal

①threadlocal是java提供的线程本地存储机制，可以将数据存储在某个线程内部，该线程可以在任意时刻，任意方法中获取缓存的数据

②ThreadLocal底层通过threadlocalMap来实现，每个Thread对象（注意不是ThreadLocal对象）中都存在一个ThreadLocalMap,Map的key为threadLocal对象，Map的value为需要缓存的值

③如果在线程池中使用ThreadLocal会造成内存泄漏，因为ThreadLocal对象使用完之后，应该要把设置的key,value,也就是Entry对象进行回收，但线程池中的线程不会回收，而线程对象是通过强引用指向ThreadLocalMap,ThreadLocalMap也是通过强引用指向Entry对象，线程不被回收，Entry对象也就不会被回收，从而出现内存泄漏，解决办法是，在使用ThreadLocal对象之后，手动调用ThreadLocal的remove方法，手动清除Entry对象

④ThreadLocal经典的应用场景就是连接管理（一个线程持有一个连接，该连接对象可以在不同的方法之间进行传递，线程之间不共享一个连接）

 

## 如何查看线程死锁

①JAVA程序死锁：通过jstack命令查看
②mysql死锁：



## 如何防止线程锁

指定获取锁的顺序，并强制线程按照指定的顺序获取锁。



## 同步方法和同步代码块的区别是什么？

在Java语言中，每一个对象有一把锁。线程可以使用synchronized关键字来获取对象上的锁。synchronized关键字可应用在方法级别(粗粒度锁)或者是代码块级别(细粒度锁)。



## 在监视器(Monitor)内部，是如何做线程同步的？程序应该做哪种级别的同步？

监视器和锁在Java虚拟机中是一块使用的。监视器监视一块同步代码块，确保一次只有一个线程执行同步代码块。每一个监视器都和一个对象引用相关联。线程在获取锁之前不允许执行同步代码。



## 线程之间如何进行通讯

①线程之间可以通过内存
需要考虑并发问题，什么时候阻塞，什么时候唤醒，例如JAVA中的wait(),notify()就是阻塞和唤醒

②基于网络
通过网络连接将数据发送给对方，当然要考虑到并发问题，处理方式就是加锁等方式。



## String,StringBuffer和StringBuilder(JDK1.5)

String是final修饰的，不可变，每次进行变量更改都产生新的String对象
StringBuffer和StringBuilder都是在原对象上进行操作。
StringBuffer是线程安全的，是synchronized修饰的，StringBuffer线程是不安全的
性能上 StringBuilder>StringBuffer>String
如果经常改变字符串建议使用后两个优先使用StringBuilder，多线程使用StringBuffer



## Sleep和wait方法有什么区别

所属类不同 sleep是thread中的方法，wait是Object的方法
方法类型不同，sleep是静态方法，wait是一个实例方法
语法不同，sleep可以直接调用，wait需要synchronized
唤醒方式不同，sleep必须传时间，wait可以传时间，也可以通过notify或notifyall唤醒
释放锁资源不用 sleep在休眠时不会释放锁，wait则会释放锁
线程状态不同，sleep时线程是waitting状态，wait线程转台是time_waitting 



## ReentranLock和synchronized

























# JVM

## JAVA类加载方法

1.由 new 关键字创建一个类的实例（静态加载）
在由运行时刻用 new 方法载入
如：Dog dog ＝ new Dog();

2.调用 Class.forName() 方法
通过反射加载类型，并创建对象实例
如：Class clazz ＝ Class.forName("Dog");
Object dog ＝clazz.newInstance();

3.调用某个 ClassLoader 实例的 loadClass() 方法
通过该 ClassLoader 实例的 loadClass() 方法载入。应用程序可以通过继承 ClassLoader 实现自己的类装载器。
如：Class clazz ＝ classLoader.loadClass("Dog")；
Object dog ＝clazz.newInstance();

区别：1和2使用的 类加载 器是相同的，都是当前类加载器。（即：this.getClass.getClassLoader）。
3由用户指定类加载器。如果需要在当前类路径以外寻找类，则只能采用第3种方式。第3种方式加载的类与当前类分属不同的命名空间。
另外：
1是静态加载，2、3是动态加



## JVM虚拟机有哪些部分
类装载子系统->运行时数据区(内存模型)->字节执行引擎

运行时数据区包含:
①方法区(1.7版本叫永久代，1.8版本开始叫元空间)，储存常量，静态变量，类信息
②堆
③虚拟机栈
④本地方法栈
⑤程序计数器


程序计数器：用来放置正在运行或者即将运行的代码的行数

 

## JVM中哪些是共享区
方法区，堆是共有的，虚拟机栈，本地方法栈，程序计数器是非共享的

 

## 什么是gc root （garbage collect）

JVM在进行垃圾回收时，需要找到没有引用的垃圾对象，但是直接找垃圾对象比较费事，所以反过来，先找非垃圾对象，那么需要从根节点开始查找（没有被引用的称为根节点），根节点被称为gc root

 

## 如何排查JVM的问题

①常用命令：jmap来查看JVM各个区域的使用情况
	jstack来查看线程的运行情况，比如阻塞和死锁
	jstat来查看垃圾回收情况，特别是fullgc,如果fullgc频繁，则需要调优
②使用工具：例如jvisualvm
③同时，还可以找到占用CPU最多的线程，定位到具体的方法，优化这个方法的执行，看是否能优化

 

## 频繁fullgc的原因

如果频繁繁盛fullgc但又没有内存溢出，那表示fullgc实际上是回收了很多对象，所以这些对象最好能在younggc过程中就直接回收掉，避免这些对象进入到老年时代，这种情况，就要考虑这些存活时间不长的对象是不是太大导致年轻带放不下，直接进入老年代。

解决办法：尝试加大年轻带的内存大小

 

## JDK1.7和1.8中JVM存在哪些变化

1.7中存在永久代，1.8中没有永久代。替代它的是元空间，元空间所占的内存不是在虚拟机内部，而是本地内存空间，这么做的原因是，不管是永久代还是元空间，他们都是方法区的具体实现，之所以元空间所占的内存改成本地内存，官方的说法是为了和JRockit统一。不过额外还有一些原因，比如方法区所储存的类信息通常是比较难确定的，所以对于方法区的大小是比较难指定的，太小了容易出现方法区溢出，太大了又会占用了太多虚拟机的内存空间，而转移到本地内存后则不会影响虚拟机所占用的内存。





































# Spring

## Spring结构

![2](.\image\2.jpg)

Spring core:提供了基本功能，包括IOC DI
Spring beans:提供了BeanFactory
spring contexrt:构建于core的context封装包，提供了事务的访问对象
spring JDBC:简化版JDBC

## 使用Spring框架的好处是什么?

轻量：Spring 是轻量的，基本的版本大约2MB。
控制反转：Spring通过控制反转实现了松散耦合，对象们给出它们的依赖，而不是创建或查找依赖的对象们。
面向切面的编程(AOP)：Spring支持面向切面的编程，并且把应用业务逻辑和系统服务分开。
容器：Spring 包含并管理应用中对象的生命周期和配置。

## Spring框架的设计模式

**使用简单工厂模式：**

简单工厂模式又叫静态工厂方法，其实质是由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类。
其中Spring中的BeanFactory就是简单工厂模式的体现，BeanFactory是Spring IOC容器中的一个核心接口，它的定义如下：
我们可以通过它的具体实现类（比如ClassPathXmlApplicationContext）来获取Bean：

**工厂方法模式**

在简单工厂中，由工厂类进行所有的逻辑判断、实例创建；如果不想在工厂类中进行判断，可以为不同的产品提供不同的工厂，不同的工厂生产不同的产品，每一个工厂都只对应一个相应的对象，这就是工厂方法模式。







## 什么是Spring beans?

Spring beans 是那些形成Spring应用的主干的java对象。它们被Spring IOC容器初始化，装配，和管理。这些beans通过容器中配置的元数据创建。比如，以XML文件中 的形式定义。
Spring 框架定义的beans都是单件beans。在bean tag中有个属性”singleton”，如果它被赋为TRUE，bean 就是单件，否则就是一个 prototype bean。默认是TRUE，所以所有在Spring框架中的beans 缺省都是单件。



## Spring配置文件中的Bean的scope(作用域)有几种

Singleton:默认的，单例。在读取xml配置文件时创建对象实例。同一个bean对象地址相同。只要容器在就一直存在。
Prototype:多例的。在使用getBean()方法时创建对象实例。每次创建时地址不同。最终被gc回收。
Request:WEB项目中使用
Session: WEB项目中使用
Global session: WEB项目中使用



## Spring框架中的单例bean是线程安全的吗?

如果Bean是无状态的，那么是线程安全的
如果Bean是有状态的，那么就需要开发人员自己来保证线程安全，最简单的办法就是改变bean的作用域把singleton改成prototype，这样每次请求bean对象就相当于是创建新的对象来保证线程的安全
如果在bean中声明任何有状态的实例变量或者类变量，推荐大家使用ThreadLocal把变量变成线程私有，如果bean的实例变量或者类变量需要在多个线程之间共享，那么就只能使用synchronized，lock，cas等这些实现线程同步的方法了。

## 解释Spring框架中bean的生命周期

1.通过反射的方式进行对象的创建
2.设置对象属性
3.如果对象中需要引用容器内部的对象，那么需要调用aware接口的子类方法来进行统一的设置
4.对生成的bean对象进行BeanPostProcessor的前置的处理工作
5.判断当前bean对象是否设置了InitializingBean接口，然后进行属性的设置等基本工作
6.如果当前bean对象定义了初始化方法，那么在此处调用初始化方法
7.对生成的bean对象进行BeanPostProcessor后置处理的处理工作
8.注册必要的Destruction相关回调接口
9.通过容器来获取对象并进行使用
10.判断是否实现了DisposableBean接口，并调用具体的方法来进行对象的销毁工作
11.如果当前bean对象定义了销毁方法，那么在此处调用销毁方法

## 什么的是bean的自动装配，它有哪些方式？

 bean的自动装配指的是bean的属性值在进行注入的时候通过某种特定的规则和方式去容器中查找，并设置到具体的对象属性中，主要有五种方式：

 no – 缺省情况下，自动配置是通过“ref”属性手动设定，在项目中最常用
 byName – 根据属性名称自动装配。如果一个bean的名称和其他bean属性的名称是一样的，将会自装配它。
 byType – 按数据类型自动装配，如果bean的数据类型是用其它bean属性的数据类型，兼容并自动装配它。
 constructor – 在构造函数参数的byType方式。
 autodetect – 如果找到默认的构造函数，使用“自动装配用构造”; 否则，使用“按类型自动装配”。



## 单例Bean和原型Bean

为了实现单例bean,就有了单例池，每次去获取这个bean的时候，就直接从单例池里面去获取。

单例池：spring源码中的定义为Map<String, Object> singletonObjects = new ConcurrentHashMap<>(256)。
其意义即为存储spring生成的单例Bean。如上，单例池实际在底层就是一个HashMap

设置方法
1.变作⽤域范围的@Scope：指定Bean的作⽤范围。属性：value指定范围的值。默认是单例的，如果像设置为多列的，只需在类中加@Scope("prototype")
2.在xml文件中添加bean的属性 scope = "prototype"



## DI的注解

@Value注⼊基本数据类型和String类型数据，它的属性value⽤于指定值。
@Autowired这个⽤法是⽐较重要的，它能够⾃动按照类型注⼊。
@Qualifier⾃动按照类型的基础上，再按照Bean的id注⼊。它在给字段注⼊时不能独⽴使⽤，必须和@Autowired⼀起使⽤，但是给⽅法参数注⼊时，可以独⽴使⽤。
@Resource：直接按照Bean的id注⼊，它只能注⼊其它的Bean类型。属性：name指定Bean的id。



## Bean生命周期

@PostConstruct注解，加在⽅法上指定Bean对象创建好之后，调⽤该⽅法初始化对象，类似于xml的init-method⽅法。

@PreDestroy注解，指定Bean销毁之前，调⽤该⽅法，类似与xml的destroy-method⽅法。注意的是如果你要想看当前的效果，就必须要调⽤ClassPathXmlApplicationContext.close( )⽅法，同时scope的值要是singleton。是在销毁之前执⾏。



## Spring的常见注解

1、@controller 控制器（注入服务）
用于标注控制层，相当于[struts](https://so.csdn.net/so/search?q=struts&spm=1001.2101.3001.7020)中的action层

2、@service 服务（注入dao）
用于标注服务层，主要用来进行业务的逻辑处理

3、@repository（实现dao访问）
用于标注数据访问层，也可以说用于标注数据访问组件，即DAO组件.

4、@component （把普通pojo实例化到spring容器中，相当于配置文件中的 <bean id="" class=""/>）
泛指各种组件，就是说当我们的类不属于各种归类的时候（不属于@Controller、@Services等的时候），我们就可以使用@Component来标注这个类。



## 控制反转IOC

就是应用本身不负责依赖对象的创建和维护，依赖对象的创建和维护都是由外部容器负责的。
**IOC创建对象的几种方式**
1）调用无参数构造器

2）带参数构造器
按名称，按下标，按顺序

3）工厂创建对象
工厂类：静态方法创建对象
工厂类：非静态方法创建对象



## AOP

面向切面:在运行时，动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面的编程

常用注解：
• @aspect 定义切面，
声明这是一个切面类（使用时需要与@Component注解一起用，表明同时将该类交给spring管理）
• @pointcut 定义切点 
别名-别的切点引用@pointcut中的value

• @before 标注Before Advice定义所在的方法
方法是public
方法没有返回值
方法没有参数，或者是入参是JoinPoint

• @afterreturning 标注After Returning Advice定义所在的方法
方法是public
入参是目标方法的返回值
自身没有返回值

• @afterthrowing 标注After Throwing Advice定义所在的方法
• @after 标注 After(Finally) Advice定义所在的方法
• @around 标注Around Advice定义所在的方法
访问权限是public
方法有返回值，返回值就是目标方法值
方法有入参，是JoinPoint的子类ProceedingJoinPoint

Aspect(切面): 是通知和切入点的结合,通知和切入点共同定义了关于切面的全
部内容—它的功能、在何时和何地完成其功能
joinpoint(连接点):所谓连接点是指那些被拦截到的点。在spring中,这些点指的
是方法,因为spring只支持方法类型的连接点.
Pointcut(切入点):所谓切入点是指我们要对哪些joinpoint进行拦截的定义.
通知定义了切面的”什么”和”何时”，切入点就定义了”何地”.
Advice(通知):所谓通知是指拦截到joinpoint之后所要做的事情就是通知.通知分
为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能)
Target(目标对象):代理的目标对象
Weaving(织入):是指把切面应用到目标对象来创建新的代理对象的过程.切面在
指定的连接点织入到目标对象
Introduction(引入):在不修改类代码的前提下, Introduction可以在运行期为类
动态地添加一些方法或Field.



## 切面的执行顺序

环绕通知的前置通知 -> 前置通知 -> 业务 -> 环绕通知的后置通知 -> 最终通知 -> 后置通知



## Spring中的AOP底层实现原理

动态代理

JDK动态代理和CGLIB动态代理
JDK代理使用的是反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。
CGLIB代理使用字节码处理框架asm，对代理对象类的class文件加载进来，通过修改字节码生成子类。

JDK代理
 1.实现InvocationHandler接口，重写invoke()
 2.使用Proxy.newProxyInstance()产生代理对象
 3.被代理的对象必须要实现接口

CGLib 必须依赖于CGLib的类库,需要满足以下要求：
 1.实现MethodInterceptor接口，重写intercept()
 2.使用Enhancer对象.create()产生代理对象

如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP，可以强制使用CGLIB实现AOP
如果目标对象没有实现了接口，必须采用CGLIB库

项目中，比如事务，权限控制，方法执行市场日志都是通过AOP技术实现的，凡是需要对某些方法做统一处理的都可以用AOP来实现，利用AOP可以做到业务无入侵


## Spring mvc 的执行流程

1.客户端发http请求，服务器接收到请求，如果匹配DispatchServlet的请求映射路径（在web.xml中指定），web容器将请求转发交给DispatchServlet处理。
2.DispatchServlet根据请求的信息（包括URL,http方法，请求报文头，请求参数，cookie等）及HandlerMapping的配置找到处理请求的的处理器（Handler）。
3.得到请求的Handler后，通过HandlerAdapter对Handler进行封装，再以统一的适配器接口调用Handler。HandlerAdapter是一个适配器，它用统一的接口对各种Handler方法进行调用
4.处理器完成业务逻辑处理后将返回一个ModelAndView给DispatchServlet, ModelAndView包含了视图逻辑名和模型数据信息。
5.当得到真实的视图队形view后，DispatchServlet就使用这个view对象，对ModelAndView中的模型数据进行视图渲染。
6.客户端得到响应消息，可能是HTML、xml、json等不同的媒体格式。

## Spring中后置处理器的作用

Spring中的后置处理器分为BeanFactory后置处理器和Bean后置处理器，它们是Spring底层源码架构设计中非常重要的一种机制，同时开发者也可以利用这两种后置处理器来进行扩展。BeanFactory后置处理器表示针对BeanFactory的处理器，Spring启动过程中，会先创建出BeanFactory实例，然后利用BeanFactory处理器来加工BeanFactory,比如Spring的扫描就是基于BeanFactory后置处理器来实现的。而Bean后置处理器来实现的，Spring在创建一个Bean的过程中，首先会实例化得到一个对象，然后再利用Bean后置处理器来对该实例对象进行加工，比如我们常说的依赖注入就是基于一个Bean后置处理器来实现的，通过该Bean后置处理器来给实例对象中加了@Autowired注解的属性自动赋值。还比如我们常说的AOP，也是利用一个Bean后置处理器来实现的，基于原实例对象，判断是否需要进行AOP，如果需要，那么就基于原实例进行动态代理，生成一个代理对象。

 

## 说一下Spring的事务机制

a.Spring事务底层是基于数据库事务和AOP机制的
b.首先对于使用了@Transactional注解的Bean,Spring会创建一个代理对象作为Bean
c.当调用代理对象的方法时，会先判断该方法上是否加了@Transactional注解
d.如果加了，那么则利用事务管理器创建一个数据库连接
e.并且修改数据库连接的autocommit属性为false,禁止此连接的自动提交，这是实现Spring事务非常重要的一步
f.然后执行当前方法，方法中执行sql
g.执行完当前方法后，如果没有出现异常就直接提交事务
h.如果出现异常，并且这个异常是需要回滚的就会回滚事务，否则仍然提交事务。
i.Spring事务的隔离级别对应的就是数据库的隔离级别
j.Spring事务的传播机制是Spring事务自己实现的，也是Spring事务中最复杂的
k.Spring事务的传播机制是基于数据库连接来做的，一个数据库连接一个事务，如果传播机制配置为需要新开一个事务，那么实际上就是先建立一个数据库连接，在此新数据库连接上执行sql

## spring事务的实现方式原理是什么？

 在使用Spring框架的时候，可以有两种事务的实现方式，一种是编程式事务，有用户自己通过代码来控制事务的处理逻辑，还有一种是声明式事务，通过@Transactional注解来实现。

 其实事务的操作本来应该是由数据库来进行控制，但是为了方便用户进行业务逻辑的操作，spring对事务功能进行了扩展实现，一般我们很少会用编程式事务，更多的是通过添加@Transactional注解来进行实现，当添加此注解之后事务的自动功能就会关闭，有spring框架来帮助进行控制。

 其实事务操作是AOP的一个核心体现，当一个方法添加@Transactional注解之后，spring会基于这个类生成一个代理对象，会将这个代理对象作为bean，当使用这个代理对象的方法的时候，如果有事务处理，那么会先把事务的自动提交给关闭，然后去执行具体的业务逻辑，如果执行逻辑没有出现异常，那么代理逻辑就会直接提交，如果出现任何异常情况，那么直接进行回滚操作，当然用户可以控制对哪些异常进行回滚操作。


## 什么时候@Transactional会失效

①因为Spring事务是基于代理来实现的，所以某个加了@Transactional的方法只有是代理对象调用时，那么这个租借才会生效，所以如果是被代理对象来调用这个方法，那么不会生效

②同时如果某个方法是private的，那么@Transactional也会失败，因为底层cglib是基于父子类来实现的，子类是不能重载父类的private方法的，所以无法很好的利用代理，也会导致@Transactional失效

 

## spring的事务传播机制是什么？

 多个事务方法相互调用时，事务如何在这些方法之间进行传播,spring中提供了7中不同的传播特性，来保证事务的正常执行：
REQUIRED：默认的传播特性，如果当前没有事务，则新建一个事务，如果当前存在事务，则加入这个事务
REQUIRED_NEW：创建一个新事务，如果存在当前事务，则挂起该事务
SUPPORTS：当前存在事务，则加入当前事务，如果当前没有事务，则以非事务的方式执行
NOT_SUPPORTED：以非事务方式执行，如果存在当前事务，则挂起当前事务
MANDATORY：必须使用事务，当前存在事务，则加入当前事务，如果当前事务不存在，则抛出异常
NEVER：不使用事务，如果当前事务存在，则抛出异常
NESTED：如果当前事务存在，则在嵌套事务中执行，否则REQUIRED的操作一样

NESTED和REQUIRED_NEW的区别：
REQUIRED_NEW是新建一个事务并且新开始的这个事务与原有事务无关，而NESTED则是当前存在事务时会开启一个嵌套事务，在NESTED情况下，父事务回滚时，子事务也会回滚，而REQUIRED_NEW情况下，原有事务回滚，不会影响新开启的事务

NESTED和REQUIRED的区别：
REQUIRED情况下，调用方存在事务时，则被调用方和调用方使用同一个事务，那么被调用方出现异常时，由于共用一个事务，所以无论是否catch异常，事务都会回滚，而在NESTED情况下，被调用方发生异常时，调用方可以catch其异常，这样只有子事务回滚，父事务不会回滚。



## spring事务什么时候会失效？

1、bean对象没有被spring容器管理
2、方法的访问修饰符不是public
3、自身调用问题
4、数据源没有配置事务管理器
5、数据库不支持事务
6、异常被捕获
7、异常类型错误或者配置错误



## 什么是Spring boot，Spring boot 有什么特性?

Spring boot 不是对Spring功能上的增强，而是提供了一种快速使用Sping的方式
用来简化spring应用的初始搭建以及开发过程 使用特定的方式来进行配置（properties或yml文件）
创建独立的spring引用程序 main方法运行
嵌入的Tomcat 无需部署war文件
简化maven配置
自动配置spring添加对应功能starter自动化配置

### 什么是Spring cloud，Spring cloud有什么特性

Spring cloud 就是一套分布式服务治理的框架，它不会提供具体功能的操作，更专注于服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等等。


## springboot常用的starter有哪些

spring-boot-starter-web 嵌入tomcat和web开发需要servlet与jsp支持
spring-boot-starter-data-jpa 数据库支持
spring-boot-starter-data-redis redis数据库支持
spring-boot-starter-data-solr solr支持
mybatis-spring-boot-starter 第三方的mybatis集成starter

## springboot自动配置的原理

在spring程序main方法中 添加@SpringBootApplication或者@EnableAutoConfiguration
会自动去maven中读取每个starter中的spring.factories文件 该文件里配置了所有需要被创建spring容器中的bean













































# MYSQL

## Mysql的各种引擎以及特点

### 1）InnoDB 

是Mysql的默认存储引擎，用于事务处理应用程序，支持外键。如果应用对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询意外，还包含很多的更新、删除操作，那么InnoDB存储引擎是比较合适的选择。InnoDB存储引擎除了有效的降低由于删除和更新导致的锁定， 还可以确保事务的完整提交和回滚，对于类似于计费系统或者财务系统等对数据准确性要求比较高的系统，InnoDB是最合适的选择。

支持事务，支持行级别锁定，支持B-tree、Full-text 等索引，不支持Hash索引

### 2）MyISAM 

如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不是很高，那么选择这个存储引擎是非常合适的。

不支持事务，支持表级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引

### 3）MEMORY

将所有数据保存在RAM中，在需要快速定位记录和其他类似数据环境下，可以提供几块的访问。MEMORY的缺陷就是对表的大小有限制，太大的表无法缓存在内存中，其次是要确保表的数据可以恢复，数据库异常终止后表中的数据是可以恢复的。MEMORY表通常用于更新不太频繁的小表，用以快速得到访问结果。

不支持事务，支持表级别锁定，支持 B-tree、Hash 等索引，不支持 Full-text 索引

Ps : Heap表，即使用MEMORY存储引擎的表

### 4）MERGE

用于将一系列等同的MyISAM表以逻辑方式组合在一起，并作为一个对象引用他们。MERGE表的优点在于可以突破对单个MyISAM表的大小限制，并且通过将不同的表分布在多个磁盘上，可以有效的改善MERGE表的访问效率。这对于存储诸如数据仓储等VLDB环境十分合适。



## MyISAM和 innodb的区别？

myisam引擎是5.1版本之前的默认引擎，支持全文检索、压缩、空间函数等，但是不支持事务和行级锁，所以一般用于有大量查询少量插入的场景来使用，而且myisam不支持外键，并且索引和数据是分开存储的。

innodb是基于聚簇索引建立的，和myisam相反它支持事务、外键，并且通过MVCC来支持高并发，索引和数据存储在一起。

1）InnoDB支持事务，MyISAM不支持，这一点是非常之重要。事务是一种高级的处理方式，如在一些列增删改中只要哪个出错还可以回滚还原，而MyISAM就不可以了。 

2）MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用 

3）InnoDB支持外键，MyISAM不支持 

4）从MySQL5.5.5以后，InnoDB是默认引擎 

5）InnoDB不支持FULLTEXT类型的索引 

6）InnoDB中不保存表的行数，如select count() from table时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count()语句包含where条件时MyISAM也需要扫描整个表 

7）对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引

8）清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表 

9）InnoDB支持行锁（某些情况下还是锁整表，如 update table set a=1 where user like ‘％lee％’。



## MQSQL为什么使用B+树

Mysql索引使用的B+树，因为索引是用来加快查询的，而B+树通过对数据进行排序所以是可以提高查询速度的，然后通过一个节点中可以存储多个元素，从而可以使得B+树的高度不会太高，在Mqsql中一个Innodb页就是一个B+树节点，一个Innodb页默认16kb，所以一般情况下一颗两层的B+树可以存2000万行左右的数据，然后通过利用B+树叶子节点存储了所有数据并且进行了排序，并且叶子节点之间有指针，可以很好的支持全表扫描，范围查找等SQL语句。



## B树和B+树的区分

### B树的特点

1）节点排序

2）一个节点可以存在多个元素，多个元素也排序了

### B+树的特点

1）拥有B树的特点、

2）叶子节点之间有指针

3）非叶子节点上的元素在叶子节点上都冗余了，也就是叶子节点中储存了所有的元素，并且排好顺序。



## ACID靠什么保证的呢？

A 原子性由undo log日志保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功的sql

C 一致性一般由代码层面来保证

I 隔离性由MVCC来保证

D 持久性由内存+redo log来保证，mysql修改数据同时在内存和redo log记录这次操作，事务提交的时候通过redo log刷盘，宕机的时候可以从redo log恢复



## Innodb如何实现事务

Innodb通过Buffer Pool,LogBuffer,Rodo Log,Undo Log来实现事务，

以update为例

1）innodb在收到一个update语句后，会先根据条件找数据所在的页，并将该页缓存在Buffer Pool中

2）执行update语句，修改Buffer Pool中的数据，也就是内存中的数据

3）针对update语句生成一个Redolog对象，并存入LogBuffer中

4）针对update语句生成undolog日志，用于事务回滚。

5）如果事务提交，那么则把Redolog对象进行持久化，后续还有其他机制将Buffer Pool中所修改的数据页持久化到磁盘中

6）如果事务回滚，则利用Undolog日志回滚。



## Mysql索引分类

1）普通索引index :加速查找

2）唯一索引

  主键索引：primary key ：加速查找+约束（不为空且唯一）

  唯一索引：unique：加速查找+约束 （唯一）

3）联合索引

  -primary key(id,name):联合主键索引

  -unique(id,name):联合唯一索引

  -index(id,name):联合普通索引

4）全文索引fulltext :用于搜索很长一篇文章的时候，效果最好。

5）空间索引spatial :了解就好，几乎不用



## *聚簇索引和非聚簇索引*

聚簇索引：索引和数据在一起的

1.MyISAM使用的是非聚簇索引，树的子节点上的data不是数据本身，而是数据存放的地址。InnoDB采用的是聚簇索引，树的叶子节点上的data就是数据本身

2.聚簇索引的数据物理存放地址和索引顺序是一致的，所以一个表当中只能有一个聚簇索引，而非聚簇索引可以有多个。

3.innoDB中，优先使用主键作聚簇索引，再使用unique,否则创建一个隐藏的row-id



## 聚簇索引记录中的两个必要隐藏列

trx_id : 用来存储每次对某条聚簇索引记录修改的操作id

roll_pointer:每次对哪条聚簇索引记录有修改的时候，都会把老的版本号写入undolog日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本未位置，通过它来获取上一个版本的记录信息。（insert没有undo日志没有roll_pointer，因为他没有老版本）



## readview

开始事务时创建readview,readview维护当前活动的事务id,即未提交的事务id,排序生成一个数组

访问数据，获取数据中的trx_id（获取的是事务id最大的记录），与readview对比。

如果比readview都小，意味着可以提交，可以访问。

如果比readview都大或者在readview中，获取roll_pointer，找到上一条记录，再次对比。重复此过程，直到找到trx_id小于readview的。



## READ_COMMITTED和REPEATABLE_READ区别

READ_COMMITTED在每次查询时都会生成一个readview, REPEATABLE_READ则在第一次查询时生成一个readview。默认是REPEATABLE_READ。

 

## MySQL的锁有哪些？

### 	从颗粒度来说

#### 1）行锁（锁的颗粒度小，但是加锁的开销较大，InnDB支持）

行锁又可以分为乐观锁和悲观锁，悲观锁可以通过for update实现，乐观锁则通过版本号实现。

##### 	a.共享锁（S锁）（select table LOCK IN SHARE MODE）

​		读锁，多个事务可以对同一个数据共享一把锁，持有锁的事务都可以访问数据，但是不能修改

##### 	b.排他锁（X锁）（select table FOR UPDATE）

​		写锁，只有一个事务能够获得排他锁，其他事务都不能获取该行的锁。InnoDB会对update/delete/insert语句自动添加排他锁。

##### 	c.自增锁

​		通常这对MySQL当中的自增字段。如果有回滚的情况，数据会回滚，自增序列不会回滚

#### 2）表锁 （锁的颗粒度大，开销较小。MqISAM InnoDB都支持）

##### 	a.表共享读锁  b.表共享写锁  c.意向锁

#### 3）全局锁（Dlush tables with read lock 加锁之后整个数据库处于只读状态。一般由于全局备份）



## 常见的锁算法

记录锁：锁一条记录

间隙锁：RR隔离级别下，会加间隙锁。锁一定范围，而不所具体记录，为了产生幻读

Next-key：间隙锁+右面记录



## 脏读、幻读、不可重复读

脏读：一个事务在处理过程中读取了另外一个事务未提交的数据。

幻读：事务A读取与搜索条件相匹配的若干行。事务B以插入或删除行等方式来修改事务A的结果集，然后再提交。

不可重复读：一个事务范围内，多次查询某个数据，却得到不同的结果。



幻读和不可重复读有些类似，但是幻读强调的是集合的增减，而不是单条数据的更新。



## 乐观锁和悲观锁

悲观锁：因为每次请求都会先对数据进行加锁， 然后进行数据操作，最后再解锁。

乐观锁：操作数据时不会对操作的数据进行加锁（这使得多个任务可以并行的对数据进行操作），只有到数据提交的时候才通过一种机制来验证数据是否存在冲突(一般实现方式是通过加版本号然后进行版本号的对比方式实现)



## 什么是MVCC

MVCC叫做多版本并发控制，实际上就是保存了数据在某个时间节点的快照。不同session会看到自己特定版本的数据，版本链。
MVCC只有在READ_COMMITTED，REPEATABLE_READ下存在

| 隔离级                               | 脏读可能性 | 不可重复读可能性 | 幻读可能性     | 加锁读 |
| ------------------------------------ | ---------- | ---------------- | -------------- | ------ |
| READ_UNCOMMITTED 未提交读            | 是         | 是               | 是             | 否     |
| READ_COMMITTED 已提交读/不可重复读   | 否         | 是               | 是             | 否     |
| REPEATABLE_READ 可重复读（**默认**） | 否         | 否               | 是(innodb除外) | 否     |
| SERIALIZABLE 串行化                  | 否         | 否               | 否             | 是     |









# 中间件



## MQ的优劣势

优势  
1.解耦 

2.异步提速 
异步进行业务处理，仅发送消息到消息[队列](https://so.csdn.net/so/search?q=队列&spm=1001.2101.3001.7020)减少响应时间

3.削峰填谷

4.延迟队列
比如下订单后如果用户未付款需要**延迟对订单进行取消**，这时候可以下订单后将订单信息放入延迟队列中，延迟队列的消息过期后加入取消队列（死信队列），消费取消队列中的消息并判断订单是否已付款，如果未付款的话进行取消订单。



## 各种MQ的比较

|            | RabbitMq | ActiveMQ     | RocketMQ             | Kafaka         |
| ---------- | -------- | ------------ | -------------------- | -------------- |
| 消息吞吐量 | 万级     | 万级（次之） | 十万级               | 十万级（次之） |
| 消息延迟   | 微妙     | 毫秒         | 毫秒级               | 毫秒以内       |
| 功能特性   | 性能极好 |              | MQ性能较好，拓展性强 | 适合大数据推送 |



## MQ如何避免消息堆积

解决办法
1、提高消费者消费速率（对消费者实现集群）
2、消费者批量获取消息，减少网络传输次数



## MQ如何保证消息顺序的一致性

如果三个任务t1,t2,t3要按顺序消费，那就把他们放在一个队列中，然后只用一个消费者单线程的来处理消息。关键点就是一个队列、一个消费者、单线程，确保消息投递到同一个队列，同一个消费者消费，单线程



## MQ如何保证消息不丢失，如何保证消息的可靠性问题

1、生产者
开启消息确认机制，并在发送前对消息进行持久化（redis）
2、MQ
开启MQ的持久化
3、消费者
关闭消息自动确认机制，进行手动确认

PS:可以进行消息检测
 总体方案解决思路为：在消息生产端，给每个发出的消息都指定一个全局唯一 ID，或者附加一个连续递增的版本号，然后在消费端做对应的版本校验。

具体怎么落地实现呢？你可以利用拦截器机制。 在生产端发送消息之前，通过拦截器将消息版本号注入消息中（版本号可以采用连续递增的 ID 生成，也可以通过分布式全局唯一 ID生成）。然后在消费端收到消息后，再通过拦截器检测版本号的连续性或消费状态，这样实现的好处是消息检测的代码不会侵入到业务代码中，可以通过单独的任务来定位丢失的消息，做进一步的排查。

这里需要你注意：如果同时存在多个消息生产端和消息消费端，通过版本号递增的方式就很难实现了，因为不能保证版本号的唯一性，此时只能通过全局唯一 ID 的方案来进行消息检测，具体的实现原理和版本号递增的方式一致




## MQ如何保证消息不被重复消费（如何保证消息消费时的幂等性）

比如订单付款业务，保证客户端与服务端的交易一致性，避免多次扣款。通过业务逻辑进行处理：

1、查询订单支付状态
2、如果判断状态已经支付，直接返回结果
3、如果判断状态未支付，支付扣款并保存流水并返回支付结果

问题：保证幂等的方案是分成两步的，第2步依赖第1步的结果，无法保证原子性
因此高并发情况下可能出现的情况：在第一次请求第2步订单状态还没有修改为已支付状态第二次请求就已经到来查询，就会出现第二次请求查询时状态还是未支付状态，进行了重复支付，破坏了幂等性

可以通过分布式锁来解决，实现支付时先查询redis中是否存在订单id的key，如果不存在则可以添加订单id的key获取锁并进行查询订单支付状态，进行支付等操作，支付完成后删除redis中订单id的key进行释放锁。
这样使用redis实现分布式锁，这次订单请求完成前，下次订单请求只能等待获取锁。

## MQ保证Mysql与Redis数据一致性问题

方案1：直接删除redis缓存，让下次查询时直接查询数据库–延迟双删策略

方案2：基于canal框架订阅binlog进行同步

1、canal伪装成mysql从节点订阅mysql主节点的binlog文件
2、mysql主节点发生变化，推送binlog给canal
3、canal服务器将binlog文件转化成json对象给mq
4、消费者消费mq中的json实现异步更新缓存



## RocketMQ中的事务消息

以订单系统和库存系统为例

生产者订单消息发送一条half消息到broker,half消息对消费者是不可见的
根据是否成功向broker发送commit或rockback
如果broker一段时间发现消息没有commit或rockback，可以调用回调接口，查询订单系统。
如果消息失败，可以重试或者进入死信队列。





## redis缓存为什么要延时双删

先清缓存或者普通双删，会存在其他事务又把旧数据放到缓存里去了

![1](.\image\redis\1.jpg)

![2](.\image\redis\2.jpg)


先更新数据库，有部分事务还是会拿到旧缓存

![3](.\image\redis\3.png)

延迟双删

![4](.\image\redis\4.jpg)


但这其中难免还是会大量的查询到旧缓存数据的。这时候可以通过加锁来解决，一次性不让太多的线程都来请求，另外从图上看，我们可以尽量缩短`第一次删除缓存`和`更新数据库`的时间差，这样可以使得其他事务第一时间获取到更新数据库后的数据。

![5](.\image\redis\5.jpg)



## 单线程的redis为什么那么快

1.redis给予内存，持久化操作的时候是fork子进程和利用好Linux系统的页缓存完成，并不会影响性能 2.单线程，避免了频繁的上下文切换 3.合理的数据结构 4.采用了非阻塞IO多路复用机制，多路I/O复用是利用select.poll.epoll可以同时监察多个流的IO事件的能力。在空闲是阻塞线程，当有IO事件发生时，唤醒线程，于是程序就会轮训一遍所有的流（epoll只轮询那些这正发生的事件的流），并且只依次顺序的处理就绪的流，这种做法避免了无用的操作。

## redis线程模型

使用是file event handle , 这个文件事件处理器是单线程的，所以redis才叫做单线程的模型。它采用IO多路复用机制同时监听多个socket,根据socket上的事件来选择对应事件处理器进行处理。

多个socket可能会并发产生不同的操作，每个操作对应不用的文件事件，但是IO会监听多个socket,然后将socket产生的事件放到文件事件分配器的队列中，然后文件事件分配器交给不同的事件处理器（连接应答处理器，命令请求处理器，命令回复处理器）

![6](.\image\6.png)


## redis和memcached的区别

存储方式不同：memcache全部存在内存中
数据类型不同：redis类型较复杂
通信协议不同：
底层机制不同：redis有自己的vm机制，因为调用系统函数的话会浪费一些时间去请求和移动
value大小不同：redis能达到1GB,memcached只有1MB



## Redis五种数据类型，是什么数据结构

1.字符串
int 当采用数字时采用
raw 长字符串，长度大于39个字节
rmbstr 短字符串 长度小于39个字节

2.链表
ziplist 元素小于512个，每个元素小于64 字节
双向链表 不满足ziplist时

hash
ziplist 元素小于512个，每个元素小于64 字节
哈希表 不满足ziplist时

set
inset 元素个数小于512，所有元素都是整数
哈希表 不满足inset时

zset
zipset 元素小于128个，每个元素小于64 字节
跳表 不满足zset

跳表
将有序链表改造为近似”折半查找“的算法，可以进行快速的插入，删除，查找

![8](.\image\8.png)



## 持久化的两种方式

1.RDB 持久化方式是会在一个特定的时间间隔里面保存某个时间点的数据快照，这个快照可以理解为数据的备份文件。
两种策略：save(单线程，不允许操作)，bgsav(异步，新操作会同时写内存和磁盘)
出发方式：满足条件/手动触发

2.AOF 是一种保存执行命令的形式，它保存执行的动作。
Redis 本身提供了三种策略来实现命令的同步，分别是不进行同步，每秒同步一次，以及当有查询的时候同步一次。

3.混合持久化，4.0版本后加入混合持久化模式，AOF的升级模式

触发AOF时，会将此刻之前的内存最为快照，以RDB格式（二进制）储存在文件中。新的命令会以AOF格式（文本）写入，写入同一个文件。
这样恢复文件的时候，因为RDB格式的存在，会使恢复效率大幅提升。

![9](.\image\9.png)

Redis 在恢复数据的时候会以 AOF 文件为优先



## 什么是缓存雪崩

大量key在同一时间失效，数据库层访问压力增大，导致宕机

解决方案
1.随机设置key失效时间
2.不设置过期时间
3.定时任务取进缓存
4.在集群的情况下，可将数据分布在不同的Redis库中



## 什么是缓存穿透

请求中含有redis没有的数据，无法拦截，直接访问数据库，导致数据库宕机

解决方案
1.拉黑攻击IP
2.对请求参数进行校验，对不合规的进行拦截
3.对不存在的数据缓存到redis中，设置key,value为null，并设置一个短期的过期时间。
4.布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap（位图）中。



## 什么是缓存击穿

某一个热点key突然失效，直接访问数据库，导致数据库宕机。

解决方案
1.设置过期时间
2.增加互斥锁（分布式锁）
第一个线程访问时加锁，其他线程无法访问，第一个线程读取到数据后，将数据加载到缓存中



## Redis数据过期淘汰策略

定期删除策略
redis启用定时器监视所有的Key,如果key过期就删除
缺点：遍历数据多，消耗大。

惰性删除策略
获取key的时候判断key是否过期，过期则删除
缺点：如果key一直未使用，则一直不会被删除 

定时+惰性删除
定时随机抽取一部分的key + 惰性删除

内存淘汰机制
volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
volatile-ttl  从已设置过期时间的数据集中挑选将要过期的数据
volatile-random 从已设置过期时间的数据集中随机淘汰
allkeys-lru 内存不足以写入新数据时，删除最近最少使用的key （基于时间）
allkeys-random 从数据集中任意淘汰
no-eviction 永不过期，内存不足报错（默认）
4.0版本以后增加两种
volatile-lfu 从已设置过期时间的数据集中挑选最不经常使用的数据淘 (基于次数)
allkeys-lfu 当内存不足以容纳新数据时，移除最不经常使用的key



如果KEY过期了。master会删除它，然后向slave发送DEL命令



## redis集群的三种模式

### 1.主从模式

一个主节点，多个从节点，主节点负责读写，从节点负责读

### 2.哨兵模式

在主从模式的情况下，当主节点发生故障，从节点升级为主节点，继续对外提供服务

哨兵的作用
监控：哨兵会不断的检查你的主服务器和从服务器是否运作正常
通知：当被监控的某个 Redis 服务器出现问题时， 哨兵可以通过API向管理员或者其他应用程序发送通知
故障迁移：当主服务器不能正常工作时，哨兵会自动进行故障迁移，也就是主从切换
统一的配置管理：连接者询问哨兵取得主从的地址

哨兵原理
哨兵使用的算法核心是 Raft 算法，主要用途就是用于分布式系统，系统容错，以及Leader选举，每个哨兵都需要定期的执行以下任务

每个 哨兵会自动发现其他 哨兵和从服务器，它以每秒钟一次的频率向它所知的主服务器、从服务器以及其他 哨兵实例发送一个 PING 命令。
如果一个实例(instance)距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 那么这个实例会被 哨兵标记为主观下线。 有效回复可以是： +PONG 、 -LOADING 或者 -MASTERDOWN 。
如果一个主服务器被标记为主观下线， 那么正在监视这个主服务器的所有哨兵要以每秒一次的频率确认主服务器的确进入了主观下线状态。
如果一个主服务器被标记为主观下线， 并且有足够数量的哨兵(至少要达到配置文件指定的数量)在指定的时间范围内同意这一判断， 那么这个主服务器被标记为客观下线。
在一般情况下， 每个哨兵会以每 10 秒一次的频率向它已知的所有主服务器和从服务器发送 INFO 命令。 当一个主服务器被哨兵标记为客观下线时，哨兵向下线主服务器的所有从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
当没有足够数量的哨兵同意主服务器已经下线， 主服务器的客观下线状态就会被移除。 当主服务器重新向哨兵的 PING 命令返回有效回复时， 主服务器的主管下线状态就会被移除。



### 3.分片集群

每一个数据只存储在其中的一台机器上
每个机器上会布置哨兵模式

对key做HASH运算（CRC16），然后对16384取模，分配到不同的机器上。



## Redis 实现主从复制的原理是什么？

一、master 复制数据给 slave 的原理如下：
1.slave 启动成功之后连接到 master 后会发送一个 `sync` 命令。
2.master 接收到这个同步命令之后启动后台的存盘进程，即将内存的数据持久化到 rdb 或 aof。
3.持久化完毕之后，master 将整个数据文件传送给 slave。

二、slave 接收 master 复制过来的数据方式有两种：
全量复制：slave 刚与 master 建立连接的时候，会将接收到的 master 发来的整个数据库文件存盘并加载到内存。
增量复制：slave 已经与 master 建立好连接关系的时候，master 会将收集到的修改数据的命令传送给 slave，slave 执行这些命令，完成同步。而不是再一次重新加载整个数据文件到内存。

当然，如果 slave 与 master 断开连接，再次重连的时候还是要加载整个数据文件的。



## 什么是主从复制风暴，如何解决

主节点有多个直接下级子节点，如何同一时刻，有多个子节点连接主节点，主节点会将RDB快照发给从节点，会导致从节点压力很大。

解决办法，可以采用主-从-从模式

![10](.\image\10.png)

## 如何实现redis事务

redis通过MULTI、EXEC、WATCH来实现事务功能。会将多个命令打包成一个事务。在执行事务期间，服务器不会中断事务而去执行其他客户端的命令请求。



首先 watch 监控 key 所起的作用实际上是一个乐观锁，它所监控的是在事务期间有没有其他客户端对所监控的值进行修改，通过REDIS_DIRTY_CAS作为标志位，如果key对应的值被其他客户端修改了则开启REDIS_DIRTY_CAS，如果没有被修改则不开启REDIS_DIRTY_CAS。
然后 multi 的作用是开启事务，如果执行了 multi 则表示开启事务，那么接下来发送到客户端的命令不会立即执行，而是被加入到一个FIFO的队列中，直到遇到 exec 命令，则队列中的命令会依次执行并根据先进先出的顺序返回执行结果。
执行 exec 命令时，首先会判断REDIS_DIRTY_CAS是否开启，如果开启，说明key的值已经被其他客户端修改过了，这时就不会再执行事务队列中的命令而是会返回（nil），如果REDIS_DIRTY_CAS没有开启，说明在执行事务期间key没有被修改，则继续执行事务队列并返回执行结果。
还有一点，一个watch对应的是一个事务，再开启一个事务时需要提前设置watch

![](.\image\7.png)



## 其他问题

Redis网络抖动，频繁主从切换怎么办？
配置文件中设置cluster-node-timeout,表示节点持续失联多久才认为是客观失联

Redis集群为什么至少要三个MASTER节点
主从切换时，要求大于等于一半的master节点投票才能切换节点。

Redis集群支持批量操作/Lua操作吗？
支持，但所有KEY必须落在同一个节点。当key的hash值不同时，可以在key前加{XXX}
mset {xxxx} :1:key1 v1   {xxxx}:1:key2 v2

数据库双写不一致
使用读写锁







# 分布式

## CAP理论

C	 consistency 强一致性
各个结点之间能同步数据，在数据同步过程中，不能对外提供服务，否则会造成数据不一致。

A	 Availability 可用性
系统保证对外可用

P	 Parition Tolerance 分区容错性
在一个结点挂了的情况下不能影响整个系统

无法同时保证CAP,只能保证CP或AP



## BASE理论

BA: basically Avaliable 基本可用。
在系统故障或者访问激增的情况下，保证核心系统可用

S: Soft state 系统处于中间态，比如数据同步

E：Eventually consistent 最终一致性







## 分布式如何保证数据库ID唯一

1.UUID
2.连接同一个数据库生成ID
3.Redis,zookeeper自增主键
4.雪花算法



## 分布式锁

1.zookeeper：利用的事zookeeper的临时节点，顺序节点，watch机制来实现的，zookeeper保证了CP
2.Redis：利用了redis的setnx，redis锁是高可用的，但不可靠（一旦redis出现了数据不一致，客户端可能同时加锁）保证了AP



## 分布式事务实现

1.插入数据库，定时任务执行
2.RocketMQ事务消息
3.seata框架：支持AT、TCC模式



## 其他问题

eureka和zk的区别

ZK:保证了CP,eureka保证了AP





# zookeeper

## zk的应用场景

1.配置中心
2.负载均衡：提供服务者列表
3.命名服务
4.分布式协调/通知
5.集群管理：集群中每台机器上部署一个agent，由agent主动想指定的监控中心系统上报自己所在的机器状态。
6.Master选举
7.分布式锁
8.分布式队列FIFO/Barrier

详情：https://blog.csdn.net/m0_58554082/article/details/118482532



## zk数据模型

1.zk的数据模型也可以理解为linux/unix的文件目录：/usr/local
2.每一个节点都称之为znode，它可以有子节点，也可以又数据。并以 key/value 形式存储数据。
3.每个节点分为临时节点和永久节点，临时节点在客户端断开后消失
4.每个zk节点都有各自的版本号，可以通过命令行来显示节点信息。
5.每当节点数据发生变化，那么该节点的版本会累加（乐观锁）
6.删除/修改过时节点，版本号不匹配会报错。
7.每个zk节点存储的数据不宜过大，几K即可。
8.节点可以设置权限acl（权限控制列表），可以通过权限来限制用户的访问。

## 节点类型

1.永久节点就是一个永久化的过程。比如说存了一些数据，这些数据只有在人为的情况下才能进行删除，如果客户端session丢失之后，或者筛选超时，那么它的数据还是会存在的。
2.临时节点也可以人为的去操作，人为的去删除。session失效之后，里面所有的数据全都会丢失。
3.有序节点，自增后缀。



## 节点内容

czxid:创建节点的事务id
mzxid:创建节点的事务id
pzxid:子节点最后一次别修改的事务id
ctime:创建时间
mtime:最后更新时间
version：版本号
cversion:子节点版本号
ephemeralOwner:创建节点的sessionid，如果是持久节点则为0
dataLenght:数据内容长度
numChildren:子节点个数





## ZAB协议（Zookeeper 原子广播协议）

ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）。

Zookeeper 是一个为[分布式](https://so.csdn.net/so/search?q=分布式&spm=1001.2101.3001.7020)应用提供高效且可靠的分布式协调服务。在解决分布式一致性方面，Zookeeper 并没有使用 Paxos ，而是采用了 ZAB 协议。

ZAB 协议定义：**ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持 `崩溃恢复` 和 `原子广播` 协议**。下面我们会重点讲这两个东西。



## ZAB协定的四种状态：

Looking：选举状态
Following：从节点所处状态
Leading：主节点所处状态
Observing：观察者状态



## ZAB协议原理

ZAB协议要求每个leader都要经历三个阶段，即发现，同步，广播。
发现：即要求zookeeper集群必须选择出一个leader进程，同时leader会维护一个follower可用列表。将来客户端可以这follower中的节点进行通信。
同步：leader要负责将本身的数据与follower完成同步，做到多副本存储。这样也是体现了CAP中高可用和分区容错。follower将队列中未处理完的请求消费完成后，写入本地事物日志中。
广播：leader可以接受客户端新的proposal请求，将新的proposal请求广播给所有的follower。



## zookeeper领导者选举

(1) 每个Server发出一个投票。由于是初始情况，ZK1和ZK2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时ZK1的投票为(1, 0)，ZK2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。
(2) 接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。
(3) 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行比较，规则如下
· 优先检查ZXID。ZXID比较大的服务器优先作为Leader。
· 如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。
对于ZK1而言，它的投票是(1, 0)，接收ZK2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时ZK2的myid最大，于是ZK2胜。ZK1更新自己的投票为(2, 0)，并将投票重新发送给ZK2。
(4) 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于ZK1、ZK2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出ZK2作为Leader。
(5) 改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。当新的Zookeeper节点ZK3启动时，发现已经有Leader了，不再选举，直接将直接的状态从LOOKING改为FOLLOWING。





## 主从数据同步（ZAB协议）

![17](.\image\17.png)

客户端发起一个写操作请求
Leader服务器将客户端的request请求转化为事物proposql提案，同时为每个proposal分配一个全局唯一的ID，即ZXID。
leader服务器与每个follower之间都有一个队列，leader将消息发送到该队列
follower机器从队列中取出消息处理完(写入本地事物日志中)毕后，向leader服务器发送ACK确认。
leader服务器收到半数以上的follower的ACK后，即认为可以发送commit
leader向所有的follower服务器发送commit消息。



## 崩溃恢复

ZAB协议崩溃恢复要求满足如下2个要求：
**确保已经被leader提交的proposal必须最终被所有的follower服务器提交。**
**确保丢弃已经被leader出的但是没有被提交的proposal**

zookeeper集群中为保证任何所有进程能够有序的顺序执行，只能是leader服务器接受写请求，即使是follower服务器接受到客户端的请求，也会转发到leader服务器进行处理。

如果leader服务器发生崩溃，则zab协议要求zookeeper集群进行崩溃恢复和leader服务器选举。

根据上述要求，新选举出来的leader不能包含未提交的proposal，即新选举的leader必须都是已经提交了的proposal的follower服务器节点。同时，新选举的leader节点中含有最高的ZXID。这样做的好处就是可以避免了leader服务器检查proposal的提交和丢弃工作。

leader服务器发生崩溃时分为如下场景：
leader在提出proposal时未提交之前崩溃，则经过崩溃恢复之后，新选举的leader一定不能是刚才的leader。因为这个leader存在未提交的proposal。
leader在发送commit消息之后，崩溃。即消息已经发送到队列中。经过崩溃恢复之后，参与选举的follower服务器(刚才崩溃的leader有可能已经恢复运行，也属于follower节点范畴)中有的节点已经是消费了队列中所有的commit消息。即该follower节点将会被选举为最新的leader。剩下动作就是数据同步过程。



## ZK的四种数据同步类型

peerLastZxid:Learner服务器（Follower或observer）最后事务ID
minCommittedLog:Leader服务器proposal缓存对垒CommittedLog中的最小zxid
maxCommittedLog:Leader服务器proposal缓存对垒CommittedLog中的最大zxid
数据同步的四种类型
1.DIFF:直接差异化同步
follower的peerLastZxid介于minCommittedLog和maxCommittedLog之间

2.TRUNC回滚
peerLastZxid大于maxCommittedLog

3.TRUNC+DIFF
Leader发现Learner包含了一条自己没有的事务记录

4.SNAP全量同步
peerLastZxid大于maxCommittedLog

初始化阶段，Leader会优先以全量同步的方式来同步
learner先向leader注册，上报peerLastZxid



## ZK的watch机制

添加watch
1.静态添加：new Zookeeper(String connectString , int sessionTimeout , watcher watcher)
这个watcher将会作为整个zookeeprt回话期间的上下文，一直报错在客户端ZKWatchManger的defaultWatcher
也可以动态添加watcher：getData()，exists，getChildren

分布式情况下的观察者模式：通过客户端和服务端分别创建观察者列表ZKWatchManager。客户端调用接口时，首先将对应的watch事件放到本地的ZKWatchManager中进行管理。服务端在接收到客户端的请求后根据请求类型判断是否含有watch事件，并将对应的事件放到ZKWatchManager中管理。
在事件触发的时候，服务端通知客户端。客户端会查询本地ZKWatchManager是否有这个watch,有的话就会回调。

![15](.\image\15.png)

![16](.\image\16.png)





## ZK分布式锁

## 读锁

读锁：大家都可以读。在没有写锁的情况下可以加写锁

创建一个临时节点，数据类型是read,
获取比自己序号小的所有节点
判断序号最小的是不是读锁
	如果是读锁的话，则上锁成功
	如果不是的话，则上锁失败。阻塞等待，当最小的节点发生变化时，会通知当前节点。

### 写锁

写锁：只有得到才能写。在没有任何锁的情况下，可以上写锁

创建一个临时节点，数据类型是write
获取ZK中所有子节点,判断自己是不是最小的节点
	如果是，上锁成功
	如果不是，监听自己的上一个节点（序号比自己少1的节点）。如果上一个节点删掉了，则自己可以上锁。



## ZK如何保证事务（原子性）

通过multiop来保证
multiop提供了creat，delete，set等方法。multiop的方法调用时，将操作保存在客户端，整体成功后会提交客户端。

同步：方法调用时直接报错
异步：对同一个multiop对象操作时，会有相同的版本号，如果有一个操作是失败的话，该版本所有的操作都会失败。



## 其他问题

如果一个客户端A修改数据，另一个客户端B去查，能否查到最新值
不一定，主从同步需要一定的时间。如果B客户端使用sycn方法先同步，再查一定是最新的































# 数据结构

## 二叉搜索树（BST）

1.左子树上所有的节点的值均小于或等于它的根节点的值

2.右子数上所有的节点的值均大于或等于它的根节点的值

3.左右子树也一定分别为二叉排序树

 

## 平衡二叉搜索树（AVL）

1.左右子树深度之差的绝对值不超过1;

2.左右子树仍然为平衡二叉树.

 

## 红黑树（RBT）

根节点是黑色的，红黑相间，

1.每个结点要么是红的，要么是黑的。

2.根结点是黑的。

3.每个叶结点，即空结点（NIL）是黑的。

4.如果一个结点是红的，那么它的俩个儿子都是黑的。

5.对每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑结点。

 

性质1：从根节点到叶节点的最长路径不大于最短路径的两倍

性质2：有n个内部节点的红黑树高度h<=2log2(n+1)

红黑树查找操作时间复杂度 = O(log2n)

 

## B-树

1.B-树的每个非叶子节点的子节点个数都不会超过D(D为B-树的阶)

2.所有的叶子节点都在同一层，

3.所有节点关键字都是按照递增顺序排列

 

## B+树

1.非叶子节点不存储数据，只进行数据索引

2.所有数据存在叶子节点当中

3.每个叶子节点都存在相邻叶子节点的指针

4.叶子节点按照本身关键字从小到大排列

 

## 数据结构的差别

AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多；

红黑是弱平衡的，用非严格的平衡来换取增删节点时候旋转次数的降低；

所以简单说，搜索的次数远远大于插入和删除，那么选择AVL树，如果搜索，插入删除次数几乎差不多，应该选择RB树。`	



## 布隆过滤器

如下就是一个简单的布隆过滤器示意图，其中k1、k2代表增加的元素，a、b、c即为无偏hash函数，最下层则为二进制数组。

![11](.\image\11.png)

- 错误率越低，位数组越长，控件占用较大
- 错误率越低，无偏hash函数越多，计算耗时较长



## 雪花算法

雪花算法是Twitter开源的分布式ID生成算法.
主要是由64bit的long型生成的全局ID,引入了时间戳和ID保持自增的属性.

64bit分为四个部分:
第一个部分是1bit, 这不 使用,没有意义;
第二个部分是41bit, 组成时间戳;
第三个部分是10bit, 工作机器ID,里面分为两个部分,5个bit是的是机房号,代表最多有2*5即32个机房,5个bit是指机器的ID,代表最多有2*5个机器,即32个机器 .
第四部分是12bit, 代表是同一个毫秒类产生不同的ID,区分同一个毫秒内产生的ID.![12](.\image\12.png)
